{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark\n",
    "\n",
    "Es un motor de análisis de datos distribuido y de propósito general que facilita el procesamiento rápido y escalable de  grandes volúmenes de datos. Fue diseñado para superar las limitaciones de velocidad y flexibilidad que existían en tecnologías anteriores (como Hadoop MapReduce)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1b99e0441c0d:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_teoria</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6a6e4392d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import pandas as pd \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"pyspark_teoria\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(total_bill=16.99, tip=1.01, sex='Female', smoker='No', day='Sun', time='Dinner', size=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(sns.load_dataset(\"tips\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.77</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.88</td>\n",
       "      <td>3.12</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.78</td>\n",
       "      <td>3.23</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
       "5       25.29  4.71    Male     No  Sun  Dinner     4\n",
       "6        8.77  2.00    Male     No  Sun  Dinner     2\n",
       "7       26.88  3.12    Male     No  Sun  Dinner     4\n",
       "8       15.04  1.96    Male     No  Sun  Dinner     2\n",
       "9       14.78  3.23    Male     No  Sun  Dinner     2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|total_bill| tip|   sex|\n",
      "+----------+----+------+\n",
      "|     16.99|1.01|Female|\n",
      "|     10.34|1.66|  Male|\n",
      "|     21.01| 3.5|  Male|\n",
      "|     23.68|3.31|  Male|\n",
      "|     24.59|3.61|Female|\n",
      "+----------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df[[\"total_bill\",\"tip\"]].show(5)\n",
    "df.select('total_bill', 'tip', 'sex').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>19.78594262295082</td>\n",
       "      <td>2.9982786885245902</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.569672131147541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>8.902411954856856</td>\n",
       "      <td>1.383638189001182</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9510998047322345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>3.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>50.81</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary         total_bill                 tip     sex smoker   day    time  \\\n",
       "0   count                244                 244     244    244   244     244   \n",
       "1    mean  19.78594262295082  2.9982786885245902    None   None  None    None   \n",
       "2  stddev  8.902411954856856   1.383638189001182    None   None  None    None   \n",
       "3     min               3.07                 1.0  Female     No   Fri  Dinner   \n",
       "4     max              50.81                10.0    Male    Yes  Thur   Lunch   \n",
       "\n",
       "                 size  \n",
       "0                 244  \n",
       "1   2.569672131147541  \n",
       "2  0.9510998047322345  \n",
       "3                   1  \n",
       "4                   6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('total_bill', 'double'),\n",
       " ('tip', 'double'),\n",
       " ('sex', 'string'),\n",
       " ('smoker', 'string'),\n",
       " ('day', 'string'),\n",
       " ('time', 'string'),\n",
       " ('size', 'bigint')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructField('total_bill', DoubleType(), True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"total_bill\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method withColumn in module pyspark.sql.dataframe:\n",
      "\n",
      "withColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` by adding a column or replacing the\n",
      "    existing column that has the same name.\n",
      "    \n",
      "    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
      "    a column from some other :class:`DataFrame` will raise an error.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    colName : str\n",
      "        string, name of the new column.\n",
      "    col : :class:`Column`\n",
      "        a :class:`Column` expression for the new column.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        DataFrame with new or replaced column.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This method introduces a projection internally. Therefore, calling it multiple\n",
      "    times, for instance, via loops in order to add multiple columns can generate big\n",
      "    plans which can cause performance issues and even `StackOverflowException`.\n",
      "    To avoid this, use :func:`select` with multiple columns at once.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
      "    >>> df.withColumn('age2', df.age + 2).show()\n",
      "    +---+-----+----+\n",
      "    |age| name|age2|\n",
      "    +---+-----+----+\n",
      "    |  2|Alice|   4|\n",
      "    |  5|  Bob|   7|\n",
      "    +---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.withColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: float (nullable = true)\n",
      " |-- tip: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conversión de tipos de datos, en pandas solemos usar astype()\n",
    "from pyspark.sql.functions import col \n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "\n",
    "#df_cast = df.withColumn('total_bill', col(\"total_bill\").cast('float'))\\\n",
    "    #.withColumn('tip', col('tip').cast('integer'))\n",
    "    \n",
    "#df_cast.printSchema()\n",
    "\n",
    "# Otra forma de hacerlo:\n",
    "    \n",
    "df_cast = df.withColumn('total_bill', col(\"total_bill\").cast(FloatType()))\\\n",
    "    .withColumn('tip', col('tip').cast(IntegerType()))\n",
    "    \n",
    "df_cast.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+\n",
      "|summary|       total_bill|               tip|             size|\n",
      "+-------+-----------------+------------------+-----------------+\n",
      "|  count|              244|               244|              244|\n",
      "|    min|             3.07|               1.0|                1|\n",
      "|    max|            50.81|              10.0|                6|\n",
      "|   mean|19.78594262295082|2.9982786885245902|2.569672131147541|\n",
      "+-------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregaciones\n",
    "df.select(\"total_bill\", \"tip\", \"size\").summary(\"count\", \"min\", \"max\", \"mean\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------+------+----+------+------------------+\n",
      "|summary|       total_bill|               tip|   sex|smoker| day|  time|              size|\n",
      "+-------+-----------------+------------------+------+------+----+------+------------------+\n",
      "|  count|              244|               244|   244|   244| 244|   244|               244|\n",
      "|   mean|19.78594262295082|2.9982786885245902|  NULL|  NULL|NULL|  NULL| 2.569672131147541|\n",
      "| stddev|8.902411954856856| 1.383638189001182|  NULL|  NULL|NULL|  NULL|0.9510998047322345|\n",
      "|    min|             3.07|               1.0|Female|    No| Fri|Dinner|                 1|\n",
      "|    25%|            13.28|               2.0|  NULL|  NULL|NULL|  NULL|                 2|\n",
      "|    50%|            17.78|              2.88|  NULL|  NULL|NULL|  NULL|                 2|\n",
      "|    75%|            24.08|              3.55|  NULL|  NULL|NULL|  NULL|                 3|\n",
      "|    max|            50.81|              10.0|  Male|   Yes|Thur| Lunch|                 6|\n",
      "+-------+-----------------+------------------+------+------+----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method filter in module pyspark.sql.dataframe:\n",
      "\n",
      "filter(condition: 'ColumnOrName') -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Filters rows using the given condition.\n",
      "    \n",
      "    :func:`where` is an alias for :func:`filter`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    condition : :class:`Column` or str\n",
      "        a :class:`Column` of :class:`types.BooleanType`\n",
      "        or a string of SQL expressions.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "        Filtered DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([\n",
      "    ...     (2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n",
      "    \n",
      "    Filter by :class:`Column` instances.\n",
      "    \n",
      "    >>> df.filter(df.age > 3).show()\n",
      "    +---+----+\n",
      "    |age|name|\n",
      "    +---+----+\n",
      "    |  5| Bob|\n",
      "    +---+----+\n",
      "    >>> df.where(df.age == 2).show()\n",
      "    +---+-----+\n",
      "    |age| name|\n",
      "    +---+-----+\n",
      "    |  2|Alice|\n",
      "    +---+-----+\n",
      "    \n",
      "    Filter by SQL expression in a string.\n",
      "    \n",
      "    >>> df.filter(\"age > 3\").show()\n",
      "    +---+----+\n",
      "    |age|name|\n",
      "    +---+----+\n",
      "    |  5| Bob|\n",
      "    +---+----+\n",
      "    >>> df.where(\"age = 2\").show()\n",
      "    +---+-----+\n",
      "    |age| name|\n",
      "    +---+-----+\n",
      "    |  2|Alice|\n",
      "    +---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "|     20.29|2.75|Female|    No|Sat|Dinner|   2|\n",
      "|     39.42|7.58|  Male|    No|Sat|Dinner|   4|\n",
      "|      21.7| 4.3|  Male|    No|Sat|Dinner|   2|\n",
      "|     20.69|2.45|Female|    No|Sat|Dinner|   4|\n",
      "|     24.06| 3.6|  Male|    No|Sat|Dinner|   3|\n",
      "|     31.27| 5.0|  Male|    No|Sat|Dinner|   3|\n",
      "|      30.4| 5.6|  Male|    No|Sun|Dinner|   4|\n",
      "|     22.23| 5.0|  Male|    No|Sun|Dinner|   2|\n",
      "|      32.4| 6.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     28.55|2.05|  Male|    No|Sun|Dinner|   3|\n",
      "|     34.81| 5.2|Female|    No|Sun|Dinner|   4|\n",
      "|     25.56|4.34|  Male|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtro por una columna\n",
    "# df.filter(df.total_bill > 20).show()\n",
    "df.filter(df[\"total_bill\"] > 20).show()\n",
    "# df.filter(df[\"total_bill\"] > 20).collect()[0][\"total_bill\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+---+------+----+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|\n",
      "+----------+----+----+------+---+------+----+\n",
      "|     21.01| 3.5|Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+----+------+---+------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"total_bill\"] > 20) & (df[\"tip\"] >3)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size| total_bill_iva_10|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|1.6989999999999998|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|             1.034|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva columna con el 10% de total_bill para el IVA\n",
    "df_new = df.withColumn(\"total_bill_iva_10\", df[\"Total_bill\"] *0.10)\n",
    "df_new.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_category|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|       media|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|       media|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        alta|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        alta|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        alta|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|        alta|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|       media|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|        alta|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|       media|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|        alta|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|       media|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|        alta|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|       media|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|       media|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|        alta|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|        alta|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|       media|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|        alta|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|        alta|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|        alta|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# en pan\n",
    "# das solemos aplicar una transformación utilizando apply()\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "# crear columna categórica a partir de numérica\n",
    "\n",
    "#df.withColumn(\n",
    "    #\"tip_category\", \n",
    "    #when(df[\"tip\"] <=1, \"baja\")\n",
    "    #.when((df[\"tip\"] >1) & (df[\"tip\"] <=3), \"media\")\n",
    "    #.otherwise(\"alta\")\n",
    "#).show()\n",
    "\n",
    "df.withColumn(\n",
    "    \"tip_category\", \n",
    "    when(col(\"tip\") <=1, \"baja\")\n",
    "    .when((col(\"tip\") >1) & (col(\"tip\") <=3), \"media\")\n",
    "    .otherwise(\"alta\")\n",
    ").show()\n",
    "\n",
    "# esta de arriba es la mejor opción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_category|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|       media|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|       media|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        alta|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        alta|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        alta|\n",
      "+----------+----+------+------+---+------+----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alternativa al ejemplo anterior usando User Defined Function(UDF)\n",
    "# Esto es mejor solo para casos avanzados en los que no nos rive con las funcionas que ya hay en function\n",
    "from pyspark.sql.functions import udf \n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def categorize_tip(tip):\n",
    "    if tip <= 1:\n",
    "        return \"baja\"\n",
    "    elif tip > 1 and tip <= 3:\n",
    "        return \"media\"\n",
    "    else:\n",
    "        return \"alta\"\n",
    "\n",
    "udf_categorize_tip = udf(categorize_tip, StringType()) \n",
    "df.withColumn(\"tip_category\", udf_categorize_tip(\"tip\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip| genre|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columnas\n",
    "df_renamed = df.withColumnRenamed(\"sex\", \"genre\")\n",
    "df_renamed.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+---+------+----+\n",
      "|total_bill| tip|day|  time|size|\n",
      "+----------+----+---+------+----+\n",
      "|     16.99|1.01|Sun|Dinner|   2|\n",
      "|     10.34|1.66|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|Sun|Dinner|   3|\n",
      "|     23.68|3.31|Sun|Dinner|   2|\n",
      "+----------+----+---+------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Borrar una columna\n",
    "df_dropped =df.drop(\"sex\", \"smoker\")\n",
    "df_dropped.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      3.07| 1.0|Female|   Yes|Sat|Dinner|   1|\n",
      "|      5.75| 1.0|Female|   Yes|Fri|Dinner|   2|\n",
      "|      7.25|5.15|  Male|   Yes|Sun|Dinner|   2|\n",
      "|      7.25| 1.0|Female|    No|Sat|Dinner|   1|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 4 rows\n",
      "\n",
      "+----------+----+----+------+---+------+----+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|\n",
      "+----------+----+----+------+---+------+----+\n",
      "|     50.81|10.0|Male|   Yes|Sat|Dinner|   3|\n",
      "|     48.33| 9.0|Male|    No|Sat|Dinner|   4|\n",
      "|     48.27|6.73|Male|    No|Sat|Dinner|   4|\n",
      "|     48.17| 5.0|Male|    No|Sun|Dinner|   6|\n",
      "+----------+----+----+------+---+------+----+\n",
      "only showing top 4 rows\n",
      "\n",
      "+----------+----+----+------+---+------+----+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|\n",
      "+----------+----+----+------+---+------+----+\n",
      "|     50.81|10.0|Male|   Yes|Sat|Dinner|   3|\n",
      "|     48.33| 9.0|Male|    No|Sat|Dinner|   4|\n",
      "|     48.27|6.73|Male|    No|Sat|Dinner|   4|\n",
      "|     48.17| 5.0|Male|    No|Sun|Dinner|   6|\n",
      "+----------+----+----+------+---+------+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenas por una columna (en pandas es sort_values)\n",
    "df.sort(\"total_bill\").show(4) # por defecto, ascendente\n",
    "df.sort(col(\"total_bill\").desc()).show(4) # para cambiarlo a descendente\n",
    "df.orderBy(col(\"total_bill\").desc()).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|Female|   87|\n",
      "|  Male|  157|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agrupar datos\n",
    "# equivalente a value_counts de pandas\n",
    "df.groupBy(\"sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------+------------------+\n",
      "|   sex|count_rows|    avg_total_bill|           sum_tip|\n",
      "+------+----------+------------------+------------------+\n",
      "|Female|        87|18.056896551724137|            246.51|\n",
      "|  Male|       157| 20.74407643312102|485.07000000000005|\n",
      "+------+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# similara pandas podemos usar una función de agregación para pedir varias agregaciones\n",
    "from pyspark.sql.functions import avg, count, sum\n",
    "\n",
    "df.groupBy(\"sex\").agg(\n",
    "    count(\"*\").alias(\"count_rows\"),\n",
    "    avg(\"total_bill\").alias(\"avg_total_bill\"),\n",
    "    sum(\"tip\").alias(\"sum_tip\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimina filas donde hay al menos un valor nulo:\n",
    "df_no_nulls = df.dropna()\n",
    "\n",
    "# Eliminar filas donde hay nulos solo en algunas columnas específicas:\n",
    "df.dropna(subset=[\"tip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar CSV desde pandas y luego a pyspark\n",
    "url =\"https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/tips.csv\"\n",
    "df_pandas = pd.read_csv(url)\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "df_spark.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- total_bill: float (nullable = true)\n",
      " |-- tip: float (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar CSV directamente\n",
    "import requests\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, StringType, IntegerType\n",
    "\n",
    "csv_path= '/tmp/tips.csv'\n",
    "csv_path= 'tips_csv'\n",
    "\n",
    "with open(csv_path, \"wb\") as file: # w de write -- b de binary\n",
    "    file.write(requests.get(url).content)\n",
    "    \n",
    "schema = StructType([\n",
    "    # columnas del dataset y su tipo de dato\n",
    "    StructField('total_bill', FloatType(), True),\n",
    "    StructField('tip', FloatType(), True),\n",
    "    StructField('sex', StringType(), True),\n",
    "    StructField('smoker', StringType(), True),\n",
    "    StructField('day', StringType(), True),\n",
    "    StructField('time', StringType(), True),\n",
    "    StructField('size', IntegerType(), True)\n",
    "])\n",
    "    \n",
    "df_spark = spark.read.csv(csv_path, header=True, inferSchema=False, schema=schema)\n",
    "df_spark.show(5)\n",
    "df_spark.printSchema(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos a un csv\n",
    "df.write.csv('tips_clean.csv', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducir a una sola partición (No recomendable)\n",
    "df.coalesce(1).write.csv('tips_clean.csv', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".bash_logout\n",
      ".profile\n",
      "tips_clean.csv\n",
      ".npm\n",
      "tips_csv\n",
      ".ipython\n",
      ".jupyter\n",
      ".local\n",
      ".cache\n",
      ".conda\n",
      ".config\n",
      ".wget-hsts\n",
      "work\n"
     ]
    }
   ],
   "source": [
    "# Verificar que aparece el archivo guardado:\n",
    "import os\n",
    "\n",
    "files = os.listdir('.')\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tips_clean = spark.read.csv(\"tips_clean.csv\",  header=True, inferSchema=True)\n",
    "df_tips_clean.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SparkSession.Builder.appName() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Se puede conectar con otras fuentes de datos, como MySQL\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmysqlapp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.jars\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/opt/mysql-connector-java-8.0.41.jar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Java database connectivity\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#.option(\"dbtable\", \"customers\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjdbc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjdbc:mysql://localhost:3306/testing_db\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM customer WHERE salary > 1000\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madmin\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[0;31mTypeError\u001b[0m: SparkSession.Builder.appName() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "# Se puede conectar con otras fuentes de datos, como MySQL\n",
    "spark = SparkSession.Builder.appName(\"mysqlapp\").config(\"spark.jars\", \"/opt/mysql-connector-java-8.0.41.jar\").getOrCreate()\n",
    "\n",
    "# Java database connectivity\n",
    "#.option(\"dbtable\", \"customers\")\n",
    "\n",
    "spark.read.format(\"jdbc\") \\\n",
    "            .option(\"url\", \"jdbc:mysql://localhost:3306/testing_db\") \\\n",
    "            .option(\"query\", \"SELECT * FROM customer WHERE salary > 1000\") \\\n",
    "            .option(\"user\", \"root\") \\\n",
    "            .option(\"password\", \"admin\") \\\n",
    "            .load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
